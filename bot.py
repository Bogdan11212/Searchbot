import logging
import asyncio
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from bs4 import BeautifulSoup
import aiohttp
from concurrent.futures import ThreadPoolExecutor
from googlesearch import search
from urllib.parse import quote_plus

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
API_TOKEN = "YOUR_BOT_TOKEN"
MAX_RESULTS = 5
TIMEOUT = 15
USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"

bot = Bot(token=API_TOKEN)
dp = Dispatcher()
executor = ThreadPoolExecutor()

# –ö—ç—à –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
cache = {}

async def yandex_search(query: str, num_results: int = 5):
    try:
        url = f"https://yandex.ru/search/?text={quote_plus(query)}&lr=213"
        headers = {"User -Agent": USER_AGENT}
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, headers=headers, timeout=TIMEOUT) as response:
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                results = []
                for item in soup.select('.serp-item.organic')[:num_results]:
                    link = item.select_one('.organic__url')
                    if link:
                        url = link.get('href')
                        title = link.text.strip()
                        results.append({'url': url, 'title': title})
                return results
    except Exception as e:
        logging.error(f"Yandex search error: {e}")
        return []

async def google_search(query: str, num_results: int = 5):
    try:
        loop = asyncio.get_event_loop()
        results = await loop.run_in_executor(
            executor,
            lambda: list(search(query, num_results=num_results, lang='ru'))
        )
        return [{'url': result, 'title': result} for result in results]
    except Exception as e:
        logging.error(f"Google search error: {e}")
        return []

async def perform_web_search(query: str):
    if query in cache:
        return cache[query]
    
    google_results = await google_search(query, MAX_RESULTS)
    yandex_results = await yandex_search(query, MAX_RESULTS)
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    combined = {result['url']: result for result in google_results + yandex_results}
    cache[query] = list(combined.values())
    return cache[query][:MAX_RESULTS * 2]

async def fetch_page_content(url):
    try:
        headers = {"User -Agent": USER_AGENT}
        async with aiohttp.ClientSession() as session:
            async with session.get(url, headers=headers, timeout=TIMEOUT) as response:
                content = await response.text()
                soup = BeautifulSoup(content, 'html.parser')
                
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞
                title = soup.find('title').get_text() if soup.title else url
                
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                paragraphs = soup.find_all(['p', 'article', 'div.content'])
                description = ' '.join([p.get_text().strip() for p in paragraphs[:3]])
                description = description[:300] + '...' if len(description) > 300 else description
                
                return {
                    'title': title.strip(),
                    'description': description.strip(),
                    'url': url
                }
    except Exception as e:
        logging.error(f"Error fetching {url}: {e}")
        return None

@dp.message(Command("search"))
async def handle_search(message: types.Message):
    query = message.text.split(" ", 1)[1] if len(message.text.split()) > 1 else ""
    if not query:
        return await message.answer("‚úèÔ∏è –í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã /search")
    
    await message.answer("üîç –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ Google –∏ Yandex...")
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ URL
        urls = await perform_web_search(query)
        if not urls:
            return await message.answer("üòû –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        # –ü–∞—Ä—Å–∏–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü
        tasks = [fetch_page_content(url['url']) for url in urls[:MAX_RESULTS * 2]]
        results = await asyncio.gather(*tasks)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = ["üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞:\ \n"]
        for i, result in enumerate(filter(None, results), 1):
            source = "üÖ∞Ô∏è –Ø–Ω–¥–µ–∫—Å" if "yandex" in result['url'] else "üåÄ Google"
            response.append(
                f"{i}. {source}\n"
                f"<b><a href='{result['url']}'>{result['title']}</a></b>\n"
                f"{result['description']}\n"
            )
        
        await message.answer(
            '\n'.join(response),
            parse_mode='HTML',
            disable_web_page_preview=True
        )
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–Ω–æ–ø–æ–∫ –¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
        await message.answer("üìÑ –ü–æ–∫–∞–∑–∞—Ç—å –±–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤?", reply_markup=await create_pagination_keyboard(query))
        
    except Exception as e:
        logging.error(f"Error: {e}")
        await message.answer("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞")

async def create_pagination_keyboard(query):
    keyboard = types.InlineKeyboardMarkup()
    keyboard.add(types.InlineKeyboardButton("–°–ª–µ–¥—É—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã", callback_data=f"next_results:{query}"))
    return keyboard

@dp.callback_query_handler(lambda c: c.data.startswith("next_results:"))
async def process_next_results(callback_query: types.CallbackQuery):
    query = callback_query.data.split(":")[1]
    await callback_query.answer()
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    urls = await perform_web_search(query)
    if not urls:
        return await callback_query.message.answer("üòû –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # –ü–∞—Ä—Å–∏–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü
    tasks = [fetch_page_content(url['url']) for url in urls[MAX_RESULTS:MAX_RESULTS * 2]]
    results = await asyncio.gather(*tasks)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
    response = ["üîç –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n"]
    for i, result in enumerate(filter(None, results), 1):
        source = "üÖ∞Ô∏è –Ø–Ω–¥–µ–∫—Å" if "yandex" in result['url'] else "üåÄ Google"
        response.append(
            f"{i}. {source}\n"
            f"<b><a href='{result['url']}'>{result['title']}</a></b>\n"
            f"{result['description']}\n"
        )
    
    await callback_query.message.answer(
        '\n'.join(response),
        parse_mode='HTML',
        disable_web_page_preview=True
    )

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
async def image_search(query: str):
    # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Google –∏–ª–∏ Yandex
    pass

@dp.message(Command("images"))
async def handle_image_search(message: types.Message):
    query = message.text.split(" ", 1)[1] if len(message.text.split()) > 1 else ""
    if not query:
        return await message.answer("‚úèÔ∏è –í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã /images")
    
    await message.answer("üîç –ò—â—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
    
    # –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    await image_search(query)

# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ Liama 3
async def liama_search(query: str):
    # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Liama 3
    pass

@dp.message(Command("liama"))
async def handle_liama_search(message: types.Message):
    query = message.text.split(" ", 1)[1] if len(message.text.split()) > 1 else ""
    if not query:
        return await message.answer("‚úèÔ∏è –í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã /liama")
    
    await message.answer("üîç –ò—â—É —Å –ø–æ–º–æ—â—å—é Liama 3...")
    
    # –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ–∏—Å–∫–∞ —Å Liama 3
    await liama_search(query)

async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(main())
